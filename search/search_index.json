{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Getting started \u00b6 KTracer is a Kotlin library that provides a simple tool for Ray Tracing. Learn how to use it in 5 minutes and begin to have fun, freeing your creativity! Installation \u00b6 binary \u00b6 You can download the latest stable binary distribution here . with git \u00b6 You may also want to clone the repository, in order to have all the latest updates. KTracer is built on gradle , so its installation is required for this installation procedure. You can install it here . If you have gradle installed, just run the command: git clone git@github.com:AnnaPivetta/KTracer.git When cloning from git , we recommend testing the success of the download with: ./gradlew test If everything is fine, you can build your own distribution with: ./gradlew assembleDist","title":"Installation"},{"location":"#getting-started","text":"KTracer is a Kotlin library that provides a simple tool for Ray Tracing. Learn how to use it in 5 minutes and begin to have fun, freeing your creativity!","title":"Getting started"},{"location":"#installation","text":"","title":"Installation"},{"location":"#binary","text":"You can download the latest stable binary distribution here .","title":"binary"},{"location":"#with-git","text":"You may also want to clone the repository, in order to have all the latest updates. KTracer is built on gradle , so its installation is required for this installation procedure. You can install it here . If you have gradle installed, just run the command: git clone git@github.com:AnnaPivetta/KTracer.git When cloning from git , we recommend testing the success of the download with: ./gradlew test If everything is fine, you can build your own distribution with: ./gradlew assembleDist","title":"with git"},{"location":"basic-usage/","text":"Basic usage \u00b6 Demo mode \u00b6 Once installed your KTracer , the first and very simple image you may generate is a demo. Running the command: ./KTracer demo will render the image described in the file demo.txt , which by default is the following: Demo image shows some of KTracer capability Converter mode \u00b6 If you have run the demo , you may have notice that you have obtained 2 different files. A ldr image, the one showed above, and an hdr one. This second one is useful, as it contains the raw value of pixel color, without any tone mapping or gamma correction applied. If the luminosity of the image does not satisfy you and you want to correct it, with the pfm file it will be a child's play. Just run the command: ./KTracer pfm2ldr --input <FILE IN> --output <FILE OUT> --format <FORMAT> and set the parameters: - --luminosity <LUMINOSITY> The required average luminosity - --gamma <GAMMA> The gamma factor of the monitor - --factor <FACTOR> a rescaling factor for colors (if interested, you can find more details in Shirley&Morley ) Render mode \u00b6 If you are here for realistic image generation, this is by far the most interesting and fun mode you can choose. Once you'll learn how to produce the input file for setting the scene, this command will perform the magic: ./KTracer render --inputfile <FILE IN> Even though the inputfile is the only mandatory flag, there are quite a lot of other interesting features that may be activated while rendering an image. Some of the most useful parameters are: --width | -w <WIDTH> The width of the image --height | -h <HEIGTH> The height of the image --algorithm | -a <ALGORITHM> The algorithm used to render the image. See later for further information --ldr-o | --ldroutput <FILE OUT> The name of the LDR output file --nr | -n <NUMBER OF RAYS> Number of rays generated at each surface-ray interaction --maxDepth | -Md <NUMBER OF REFLECTIONS> Maximum number of reflections per ray --rrTrigger | -rr <TRIGGER> Depth value after which Russian Roulette algorithm activates. --AAgrid | --AA | --aa | -A <NUMBER> Number of divisions in each pixel's side to perform antialiasing (more simply, <NUMBER>*<NUMBER> is the total amount of samples per pixel) Animation \u00b6 With the help of ffmpeg also beautiful animations can be rendered with KTracer . On our repository there is a script to create animations. You must have a variable in the input file that is associated to the rotation of the camera, and using it you can create your own GIF .","title":"Basic Usage"},{"location":"basic-usage/#basic-usage","text":"","title":"Basic usage"},{"location":"basic-usage/#demo-mode","text":"Once installed your KTracer , the first and very simple image you may generate is a demo. Running the command: ./KTracer demo will render the image described in the file demo.txt , which by default is the following: Demo image shows some of KTracer capability","title":"Demo mode"},{"location":"basic-usage/#converter-mode","text":"If you have run the demo , you may have notice that you have obtained 2 different files. A ldr image, the one showed above, and an hdr one. This second one is useful, as it contains the raw value of pixel color, without any tone mapping or gamma correction applied. If the luminosity of the image does not satisfy you and you want to correct it, with the pfm file it will be a child's play. Just run the command: ./KTracer pfm2ldr --input <FILE IN> --output <FILE OUT> --format <FORMAT> and set the parameters: - --luminosity <LUMINOSITY> The required average luminosity - --gamma <GAMMA> The gamma factor of the monitor - --factor <FACTOR> a rescaling factor for colors (if interested, you can find more details in Shirley&Morley )","title":"Converter mode"},{"location":"basic-usage/#render-mode","text":"If you are here for realistic image generation, this is by far the most interesting and fun mode you can choose. Once you'll learn how to produce the input file for setting the scene, this command will perform the magic: ./KTracer render --inputfile <FILE IN> Even though the inputfile is the only mandatory flag, there are quite a lot of other interesting features that may be activated while rendering an image. Some of the most useful parameters are: --width | -w <WIDTH> The width of the image --height | -h <HEIGTH> The height of the image --algorithm | -a <ALGORITHM> The algorithm used to render the image. See later for further information --ldr-o | --ldroutput <FILE OUT> The name of the LDR output file --nr | -n <NUMBER OF RAYS> Number of rays generated at each surface-ray interaction --maxDepth | -Md <NUMBER OF REFLECTIONS> Maximum number of reflections per ray --rrTrigger | -rr <TRIGGER> Depth value after which Russian Roulette algorithm activates. --AAgrid | --AA | --aa | -A <NUMBER> Number of divisions in each pixel's side to perform antialiasing (more simply, <NUMBER>*<NUMBER> is the total amount of samples per pixel)","title":"Render mode"},{"location":"basic-usage/#animation","text":"With the help of ffmpeg also beautiful animations can be rendered with KTracer . On our repository there is a script to create animations. You must have a variable in the input file that is associated to the rotation of the camera, and using it you can create your own GIF .","title":"Animation"},{"location":"input-file/","text":"The scenes to render are described in an input file , which is the only mandatory parameter for Render mode . Input file is provided also with comments, identified by the key symbol # The three main ingredients for a scene are: materials shapes camera Materials \u00b6 Each object in the scene must be made of a material, which is defined by its BRDF and its emitted radiance. Moreover, to each material you must assign a name with which you'll be able to call it all through the file. BRDF \u00b6 The BRDF describes the way the light interacts with the shape, once a ray hits it. The light can be scattered or reflected, and this behaviour affects the way we see the object. There are 2 different BRDF s available: Diffusive (Lambertian) \u00b6 Represents a completely diffusive material. When the light hits, it is scattered in random directions, thus making the object totally opaque. Specular \u00b6 As the name suggests, this BRDF describes a total reflecting surface, such as the one of an ideal mirror. When the light hits, the ray follows the law of reflection . Both BRDF s needs also a parameter: the color of the object, which is represented by a Pigment Emitted Radiance \u00b6 Emitted radiance too is defined by a Pigment . This value is the color in which the objects, eventually, radiate. For diffusive objects, it is set as uniform(<black>) , but a different choice leads to creating a source of lights in the scene. It is always necessary to have at least one source of lights in order to see the scene. Here are two examples of different material definitions: Diffusive (radiating) material sky ( diffusive ( uniform(<skyblue>) ), uniform(<skyblue>) ) ... Specular (not radiating) material mirror ( specular ( uniform(<silver>) ), uniform(<black>) ) ... Here I must put an image with both brdfs Shapes \u00b6 After having defined the materials, it's now time to build the scene you want to render. This is made by placing the available shapes wherever you like, assigning them the material they're made of. Not only the material is important, but also transformations play great role in the setting of the stage. By default, each shape is placed with its center in the point (0.0, 0.0, 0.0) of the world and has a default dimension. Both position and dimension, along with also orientation in the space, can be modified by the means of a transformation. Transformations \u00b6 If no transformation need to be applied you can simply use the keyword identity , such as in the following example ... sphere ( sky, identity ) ... Translation \u00b6 To apply a solid translation to the selected shape the keyword is translation([vec]) , where the vector generating the transformation is [vec] = [x, y, z] , specified giving its three components between squared brackets ... sphere ( sky, translation([1.0, 2.0, 0.0]) ) ... Rotations \u00b6 Rotations are always with respect to one of the 3 principal axis. The angle of rotation is expressed in degrees, and the keyword is rotation_^ , where ^ is one of x , y or z , and is the axis along which the rotation occurs. Different basic transformation may be combined into a more complex one with the help of * operator. Since they are implemented as matrices, the order in which transformations are applied is from right to left. In the following example a cube is rotated with respect to the z axis and translated along the x axis by 1.0: ... box ( (-0.5, -0.5, -0.5), (0.5, 0.5, 0.5), minecraft, translation([1.0, 0.0, 0.0]) * rotation_z(30) ) ... Here is the result of the code above (left) vs what will result by the swapping of the 2 transformations (right) Scaling \u00b6 The third possible transformation is the one that changes the dimension of the object. The scaling does not have to be homogeneous and may vary along different directions. The keyword is scaling([vec]) , where [vec] components are the scale factor along each direction. ... sphere ( mirror, scaling([1.0, 3.0, 1.0]) ) ... Inhomogeneous scaling of a sphere leads to an ellipsoid One may also want to define a variable that represents a shape, so that this can be called multiple times in the input file with the use of a simple name. This is extremely useful in the creation of complex CSG shapes. The syntax is similar to the one used for defining materials, and to call the object in the file it is sufficient to write the name, and the transformation to apply: ... shape minecraftCube box ( #Defining the shape (-0.5, -0.5, -0.5), (0.5, 0.5, 0.5), minecraft, identity ) mincraft ( rotation_z(45) ) #Placing the shape into the world ... Camera \u00b6 The last ingredient for rendering your first image is a camera from which the world is observed. Cameras accept a transformation parameter that sets its position and orientation. It also need to know the aspect ratio of the image, and the distance from the camera and the scree onto which the scene is projected (recommended is 1.0). There are two different projections available: orthogonal and perspective : Orthogonal ... camera( perspective, translation([-4,0,1]), 1.0, #Aspect Ratio 1.0 #Distance from screen ) Orthogonal projection Perspective ... camera( perspective, translation([-4,0,1]), 1.0, #Aspect Ratio 1.0 #Distance from screen ) Perspective projection","title":"Input File"},{"location":"input-file/#materials","text":"Each object in the scene must be made of a material, which is defined by its BRDF and its emitted radiance. Moreover, to each material you must assign a name with which you'll be able to call it all through the file.","title":"Materials"},{"location":"input-file/#brdf","text":"The BRDF describes the way the light interacts with the shape, once a ray hits it. The light can be scattered or reflected, and this behaviour affects the way we see the object. There are 2 different BRDF s available:","title":"BRDF"},{"location":"input-file/#diffusive-lambertian","text":"Represents a completely diffusive material. When the light hits, it is scattered in random directions, thus making the object totally opaque.","title":"Diffusive (Lambertian)"},{"location":"input-file/#specular","text":"As the name suggests, this BRDF describes a total reflecting surface, such as the one of an ideal mirror. When the light hits, the ray follows the law of reflection . Both BRDF s needs also a parameter: the color of the object, which is represented by a Pigment","title":"Specular"},{"location":"input-file/#emitted-radiance","text":"Emitted radiance too is defined by a Pigment . This value is the color in which the objects, eventually, radiate. For diffusive objects, it is set as uniform(<black>) , but a different choice leads to creating a source of lights in the scene. It is always necessary to have at least one source of lights in order to see the scene. Here are two examples of different material definitions: Diffusive (radiating) material sky ( diffusive ( uniform(<skyblue>) ), uniform(<skyblue>) ) ... Specular (not radiating) material mirror ( specular ( uniform(<silver>) ), uniform(<black>) ) ... Here I must put an image with both brdfs","title":"Emitted Radiance"},{"location":"input-file/#shapes","text":"After having defined the materials, it's now time to build the scene you want to render. This is made by placing the available shapes wherever you like, assigning them the material they're made of. Not only the material is important, but also transformations play great role in the setting of the stage. By default, each shape is placed with its center in the point (0.0, 0.0, 0.0) of the world and has a default dimension. Both position and dimension, along with also orientation in the space, can be modified by the means of a transformation.","title":"Shapes"},{"location":"input-file/#transformations","text":"If no transformation need to be applied you can simply use the keyword identity , such as in the following example ... sphere ( sky, identity ) ...","title":"Transformations"},{"location":"input-file/#translation","text":"To apply a solid translation to the selected shape the keyword is translation([vec]) , where the vector generating the transformation is [vec] = [x, y, z] , specified giving its three components between squared brackets ... sphere ( sky, translation([1.0, 2.0, 0.0]) ) ...","title":"Translation"},{"location":"input-file/#rotations","text":"Rotations are always with respect to one of the 3 principal axis. The angle of rotation is expressed in degrees, and the keyword is rotation_^ , where ^ is one of x , y or z , and is the axis along which the rotation occurs. Different basic transformation may be combined into a more complex one with the help of * operator. Since they are implemented as matrices, the order in which transformations are applied is from right to left. In the following example a cube is rotated with respect to the z axis and translated along the x axis by 1.0: ... box ( (-0.5, -0.5, -0.5), (0.5, 0.5, 0.5), minecraft, translation([1.0, 0.0, 0.0]) * rotation_z(30) ) ... Here is the result of the code above (left) vs what will result by the swapping of the 2 transformations (right)","title":"Rotations"},{"location":"input-file/#scaling","text":"The third possible transformation is the one that changes the dimension of the object. The scaling does not have to be homogeneous and may vary along different directions. The keyword is scaling([vec]) , where [vec] components are the scale factor along each direction. ... sphere ( mirror, scaling([1.0, 3.0, 1.0]) ) ... Inhomogeneous scaling of a sphere leads to an ellipsoid One may also want to define a variable that represents a shape, so that this can be called multiple times in the input file with the use of a simple name. This is extremely useful in the creation of complex CSG shapes. The syntax is similar to the one used for defining materials, and to call the object in the file it is sufficient to write the name, and the transformation to apply: ... shape minecraftCube box ( #Defining the shape (-0.5, -0.5, -0.5), (0.5, 0.5, 0.5), minecraft, identity ) mincraft ( rotation_z(45) ) #Placing the shape into the world ...","title":"Scaling"},{"location":"input-file/#camera","text":"The last ingredient for rendering your first image is a camera from which the world is observed. Cameras accept a transformation parameter that sets its position and orientation. It also need to know the aspect ratio of the image, and the distance from the camera and the scree onto which the scene is projected (recommended is 1.0). There are two different projections available: orthogonal and perspective : Orthogonal ... camera( perspective, translation([-4,0,1]), 1.0, #Aspect Ratio 1.0 #Distance from screen ) Orthogonal projection Perspective ... camera( perspective, translation([-4,0,1]), 1.0, #Aspect Ratio 1.0 #Distance from screen ) Perspective projection","title":"Camera"},{"location":"Pigments/pigments/","text":"","title":"Pigments"},{"location":"Renderers/renderers/","text":"","title":"Renderers"},{"location":"Shapes/shapes/","text":"","title":"Shapes"}]}